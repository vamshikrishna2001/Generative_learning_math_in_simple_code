{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GANs) for MNIST Generation\n",
    "\n",
    "## Overview\n",
    "\n",
    "Generative Adversarial Networks represent a breakthrough in generative modeling through adversarial training. Two neural networks compete against each other: a Generator that creates fake data and a Discriminator that tries to detect fake data.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### 1. The Minimax Game\n",
    "GANs solve a **minimax optimization problem**:\n",
    "\n",
    "$$\\min_G \\max_D V(D, G) = \\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z(z)}[\\log(1 - D(G(z)))]$$\n",
    "\n",
    "**Intuition**:\n",
    "- **Discriminator (D)**: Wants to maximize the ability to distinguish real from fake\n",
    "- **Generator (G)**: Wants to minimize the discriminator's ability to detect fakes\n",
    "\n",
    "### 2. Nash Equilibrium\n",
    "At equilibrium:\n",
    "- **Generator**: Produces data indistinguishable from real data\n",
    "- **Discriminator**: Cannot distinguish real from fake (outputs 0.5)\n",
    "- **Optimal solution**: $p_g(x) = p_{data}(x)$ (generator distribution equals data distribution)\n",
    "\n",
    "### 3. Training Dynamics\n",
    "Unlike other generative models, GANs use **adversarial training**:\n",
    "\n",
    "**Step 1**: Train Discriminator\n",
    "- Maximize ability to classify real vs fake\n",
    "- $\\max_D [\\log D(x_{real}) + \\log(1 - D(G(z)))]$\n",
    "\n",
    "**Step 2**: Train Generator  \n",
    "- Minimize discriminator's ability to detect fakes\n",
    "- $\\min_G [\\log(1 - D(G(z)))]$ or $\\max_G [\\log D(G(z))]$ (non-saturating)\n",
    "\n",
    "### 4. Loss Function Analysis\n",
    "**GAN losses are bounded** but behave differently:\n",
    "\n",
    "- **Discriminator Loss**: Binary cross-entropy ∈ [0, ∞), typically [0, 2]\n",
    "- **Generator Loss**: Binary cross-entropy ∈ [0, ∞), typically [0, 5]\n",
    "- **Ideal Training**: Both losses should converge to $\\log(2) ≈ 0.693$\n",
    "\n",
    "### 5. No Explicit Likelihood\n",
    "Unlike VAEs or flows, GANs **don't compute explicit likelihood**:\n",
    "- Cannot evaluate $p(x)$ for given data\n",
    "- Focus purely on sample quality\n",
    "- Evaluation requires external metrics (FID, IS)\n",
    "\n",
    "### 6. Direct Sampling\n",
    "**Generation Process**: $z \\sim p(z) \\rightarrow G(z) \\rightarrow x$\n",
    "- Simple sampling from noise distribution (usually $\\mathcal{N}(0, I)$)\n",
    "- No complex inversion or reparameterization needed\n",
    "- Can generate high-quality, sharp images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Implementation: Imports and Data Preprocessing\n\nUnlike flow models, GANs work perfectly with discrete pixel values and don't require dequantization:",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom keras.datasets.mnist import load_data\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\ntorch.manual_seed(0)\n\n# Load and normalize MNIST dataset - standard approach for GANs\nprint(\"Loading MNIST dataset...\")\n(trainX, trainY), (testX, testy) = load_data()\n\n# Standard normalization for GANs: just scale to [0,1]\ntrainX = np.float32(trainX) / 255.0  # No dequantization needed\ntrainX = torch.tensor(trainX.reshape(-1, 28 * 28))\n\nprint(f\"Dataset shape: {trainX.shape}\")\nprint(f\"Pixel value range: [{trainX.min():.3f}, {trainX.max():.3f}]\")\nprint(\"Note: GANs work well with discrete pixel values - no dequantization needed!\")\n\n# Set device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Network: Creating Fake Data\n",
    "\n",
    "The Generator's job is to transform random noise into realistic MNIST digits:\n",
    "\n",
    "**Architecture Design**:\n",
    "- **Input**: Random noise vector $z \\sim \\mathcal{N}(0, I)$ (dimension 100)\n",
    "- **Output**: Fake image $G(z)$ (dimension 784 for flattened 28×28)\n",
    "- **Activation**: Sigmoid to ensure output ∈ [0,1]\n",
    "\n",
    "**Key Principles**:\n",
    "- Deep enough to learn complex mappings\n",
    "- ReLU activations for non-linearity\n",
    "- Sigmoid final layer for valid pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator Network: z → x̂\n",
    "    \n",
    "    Transforms random noise into realistic MNIST digits\n",
    "    \n",
    "    Architecture: \n",
    "    noise(100) → hidden(256) → hidden(256) → hidden(256) → image(784)\n",
    "    \n",
    "    Goal: Fool the discriminator into thinking generated images are real\n",
    "    \"\"\"\n",
    "    def __init__(self, noise_dim=100, hidden_dim=256, output_dim=784):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.noise_dim = noise_dim\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Layer 1: Noise to hidden\n",
    "            nn.Linear(noise_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Layer 2-3: Hidden layers for complexity\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Output layer: Generate image\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid()  # Ensure output ∈ [0,1] for valid pixels\n",
    "        )\n",
    "        \n",
    "        print(f\"Initialized Generator:\")\n",
    "        print(f\"  Noise dimension: {noise_dim}\")\n",
    "        print(f\"  Hidden dimension: {hidden_dim}\")\n",
    "        print(f\"  Output dimension: {output_dim}\")\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Generate fake images from noise\n",
    "        \n",
    "        Args:\n",
    "            z: Random noise [batch_size, noise_dim]\n",
    "            \n",
    "        Returns:\n",
    "            fake_images: Generated images [batch_size, output_dim]\n",
    "        \"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "# Initialize generator\n",
    "noise_dim = 100\n",
    "generator = Generator(noise_dim=noise_dim).to(device)\n",
    "print(f\"\\nGenerator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "\n",
    "# Test generator\n",
    "print(\"\\nTesting generator...\")\n",
    "with torch.no_grad():\n",
    "    test_noise = torch.randn(5, noise_dim).to(device)\n",
    "    fake_images = generator(test_noise)\n",
    "    print(f\"Input noise shape: {test_noise.shape}\")\n",
    "    print(f\"Generated images shape: {fake_images.shape}\")\n",
    "    print(f\"Generated pixel range: [{fake_images.min():.3f}, {fake_images.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Network: Real vs Fake Detection\n",
    "\n",
    "The Discriminator's job is to distinguish between real MNIST digits and generator fakes:\n",
    "\n",
    "**Architecture Design**:\n",
    "- **Input**: Image (real or fake) with dimension 784\n",
    "- **Output**: Probability that input is real ∈ [0,1]\n",
    "- **Activation**: LeakyReLU (helps gradient flow) + Dropout (prevents overfitting)\n",
    "\n",
    "**Key Principles**:\n",
    "- Must be powerful enough to provide useful gradients to generator\n",
    "- Must not be too powerful (would make generator training impossible)\n",
    "- Dropout and LeakyReLU improve training stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator Network: x → [0,1]\n",
    "    \n",
    "    Distinguishes between real MNIST digits and generator fakes\n",
    "    \n",
    "    Architecture:\n",
    "    image(784) → hidden(256) → hidden(256) → hidden(256) → probability(1)\n",
    "    \n",
    "    Goal: Maximize ability to detect fake images\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=784, hidden_dim=256):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Layer 1: Image to hidden\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),  # LeakyReLU helps with gradient flow\n",
    "            nn.Dropout(0.3),    # Dropout prevents discriminator overfitting\n",
    "            \n",
    "            # Layer 2-3: Hidden layers\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Output layer: Real/fake classification\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()  # Output ∈ [0,1]: 0=fake, 1=real\n",
    "        )\n",
    "        \n",
    "        print(f\"Initialized Discriminator:\")\n",
    "        print(f\"  Input dimension: {input_dim}\")\n",
    "        print(f\"  Hidden dimension: {hidden_dim}\")\n",
    "        print(f\"  Uses LeakyReLU(0.2) and Dropout(0.3)\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Classify input as real or fake\n",
    "        \n",
    "        Args:\n",
    "            x: Input images [batch_size, input_dim]\n",
    "            \n",
    "        Returns:\n",
    "            probability: P(x is real) ∈ [0,1] [batch_size, 1]\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize discriminator\n",
    "discriminator = Discriminator().to(device)\n",
    "print(f\"\\nDiscriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "\n",
    "# Test discriminator\n",
    "print(\"\\nTesting discriminator...\")\n",
    "with torch.no_grad():\n",
    "    # Test with real data\n",
    "    test_real = trainX[:5].to(device)\n",
    "    real_predictions = discriminator(test_real)\n",
    "    \n",
    "    # Test with fake data\n",
    "    test_noise = torch.randn(5, noise_dim).to(device)\n",
    "    test_fake = generator(test_noise)\n",
    "    fake_predictions = discriminator(test_fake)\n",
    "    \n",
    "    print(f\"Real data predictions: {real_predictions.mean().item():.3f} (should be ~1.0 when trained)\")\n",
    "    print(f\"Fake data predictions: {fake_predictions.mean().item():.3f} (should be ~0.0 when trained)\")\n",
    "    print(f\"Initial difference: {real_predictions.mean().item() - fake_predictions.mean().item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Loss Functions: The Heart of GANs\n",
    "\n",
    "GANs use adversarial loss functions that create the minimax game:\n",
    "\n",
    "### Mathematical Foundation\n",
    "\n",
    "**Discriminator Loss** (wants to maximize):\n",
    "$$L_D = -\\mathbb{E}_{x \\sim p_{data}}[\\log D(x)] - \\mathbb{E}_{z \\sim p_z}[\\log(1 - D(G(z)))]$$\n",
    "\n",
    "**Generator Loss** (non-saturating version):\n",
    "$$L_G = -\\mathbb{E}_{z \\sim p_z}[\\log D(G(z))]$$\n",
    "\n",
    "### Implementation Details\n",
    "- Use **Binary Cross Entropy** loss for both networks\n",
    "- **Labels**: Real=1, Fake=0\n",
    "- **Non-saturating**: Generator maximizes $\\log D(G(z))$ instead of minimizing $\\log(1-D(G(z)))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss function and optimizers\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy for adversarial loss\n",
    "\n",
    "# Optimizers: Adam with specific hyperparameters for GANs\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "print(\"=== GAN Loss Function Demonstration ===\")\n",
    "\n",
    "# Demonstrate loss computation\n",
    "batch_size = 32\n",
    "real_images = trainX[:batch_size].to(device)\n",
    "\n",
    "# Create labels\n",
    "real_labels = torch.ones(batch_size, 1).to(device)   # Real = 1\n",
    "fake_labels = torch.zeros(batch_size, 1).to(device)  # Fake = 0\n",
    "\n",
    "print(f\"Label setup:\")\n",
    "print(f\"  Real labels: {real_labels.mean().item():.1f} (all ones)\")\n",
    "print(f\"  Fake labels: {fake_labels.mean().item():.1f} (all zeros)\")\n",
    "\n",
    "# Forward pass with current (untrained) networks\n",
    "with torch.no_grad():\n",
    "    # Discriminator on real data\n",
    "    real_outputs = discriminator(real_images)\n",
    "    d_loss_real = criterion(real_outputs, real_labels)\n",
    "    \n",
    "    # Generator creates fake data\n",
    "    noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "    fake_images = generator(noise)\n",
    "    \n",
    "    # Discriminator on fake data\n",
    "    fake_outputs = discriminator(fake_images)\n",
    "    d_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "    \n",
    "    # Generator loss (wants discriminator to output 1 for fakes)\n",
    "    g_loss = criterion(fake_outputs, real_labels)  # Note: real_labels!\n",
    "    \n",
    "    # Total discriminator loss\n",
    "    d_loss_total = d_loss_real + d_loss_fake\n",
    "\n",
    "print(f\"\\nInitial loss values (before training):\")\n",
    "print(f\"  D(real) = {real_outputs.mean().item():.3f} (should approach 1.0)\")\n",
    "print(f\"  D(fake) = {fake_outputs.mean().item():.3f} (should approach 0.0)\")\n",
    "print(f\"  Discriminator loss: {d_loss_total.item():.3f}\")\n",
    "print(f\"  Generator loss: {g_loss.item():.3f}\")\n",
    "\n",
    "print(f\"\\nLoss interpretation:\")\n",
    "print(f\"  When D(real) → 1 and D(fake) → 0: Discriminator is winning\")\n",
    "print(f\"  When D(fake) → 1: Generator is winning\")\n",
    "print(f\"  At equilibrium: D(real) ≈ D(fake) ≈ 0.5\")\n",
    "print(f\"  Perfect GAN: Both losses converge to log(2) ≈ 0.693\")\n",
    "\n",
    "# Show typical GAN loss ranges\n",
    "print(f\"\\nTypical GAN loss ranges during training:\")\n",
    "print(f\"  Discriminator loss: 0.0 - 2.0 (lower = discriminator winning)\")\n",
    "print(f\"  Generator loss: 0.0 - 5.0 (higher = discriminator winning)\")\n",
    "print(f\"  Healthy training: Both losses fluctuate around 0.5 - 1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Dynamics: The Adversarial Dance\n",
    "\n",
    "GAN training involves a delicate balance between two competing networks:\n",
    "\n",
    "### Training Algorithm\n",
    "**For each batch**:\n",
    "1. **Train Discriminator**:\n",
    "   - Forward pass on real data → maximize $\\log D(x)$\n",
    "   - Forward pass on fake data → maximize $\\log(1-D(G(z)))$\n",
    "   - Update discriminator parameters\n",
    "\n",
    "2. **Train Generator**:\n",
    "   - Generate fake data\n",
    "   - Forward pass through discriminator → maximize $\\log D(G(z))$\n",
    "   - Update generator parameters\n",
    "\n",
    "### Training Challenges\n",
    "- **Mode Collapse**: Generator produces limited variety\n",
    "- **Training Instability**: Loss oscillations, non-convergence\n",
    "- **Gradient Vanishing**: When discriminator is too good\n",
    "- **Evaluation**: No likelihood-based metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common GAN Training Challenges: What Can Go Wrong\n",
    "\n",
    "GAN training is notoriously unstable and prone to various failure modes. Understanding these issues is crucial for successful GAN training:\n",
    "\n",
    "### 1. Mode Collapse 🚨\n",
    "\n",
    "**What it is**: Generator produces limited variety of outputs, \"collapsing\" to a few modes of the data distribution.\n",
    "\n",
    "**Symptoms**:\n",
    "- Generated images look very similar\n",
    "- Generator loss decreases but diversity disappears\n",
    "- Missing entire classes of data (e.g., only generates digits 1, 3, 7)\n",
    "\n",
    "**Example Output Patterns**:\n",
    "```\n",
    "Normal: Generates all digits 0-9 with variety\n",
    "Mode Collapse: Only generates digit 3 repeatedly, or cycles between 2-3 digits\n",
    "```\n",
    "\n",
    "**Why it happens**:\n",
    "- Generator finds a few \"easy\" examples that fool the discriminator\n",
    "- No incentive to explore the full data distribution\n",
    "- Discriminator can't provide useful gradients for diversity\n",
    "\n",
    "### 2. Discriminator Collapse\n",
    "\n",
    "**What it is**: Discriminator becomes too powerful, perfectly distinguishing real from fake.\n",
    "\n",
    "**Symptoms** (exactly what you're seeing):\n",
    "```\n",
    "D_loss= 0.000, G_loss=12.840, D(x)=1.000, D(G(z))=0.000\n",
    "```\n",
    "- Discriminator loss ≈ 0 (perfect classification)\n",
    "- Generator loss very high (12+)\n",
    "- D(real) = 1.0, D(fake) = 0.0 (perfect separation)\n",
    "\n",
    "**Why it's bad**:\n",
    "- Generator gets no useful gradients (discriminator says \"definitely fake\")\n",
    "- Training stalls completely\n",
    "- Generator cannot improve\n",
    "\n",
    "**Common Causes**:\n",
    "- Discriminator learning rate too high\n",
    "- Discriminator architecture too powerful\n",
    "- Generator architecture too weak\n",
    "- Not enough generator updates per discriminator update\n",
    "\n",
    "### 3. Training Instability\n",
    "\n",
    "**Nash Equilibrium Problem**:\n",
    "- GANs seek Nash equilibrium between two players\n",
    "- Unlike single optimization, no guarantee of convergence\n",
    "- Small changes can destabilize entire training\n",
    "\n",
    "**Oscillating Losses**:\n",
    "```\n",
    "Epoch 10: G_loss=2.1, D_loss=0.3  # D winning\n",
    "Epoch 11: G_loss=0.8, D_loss=1.9  # G winning  \n",
    "Epoch 12: G_loss=3.2, D_loss=0.1  # D winning again\n",
    "```\n",
    "\n",
    "**Non-Convergent Behavior**:\n",
    "- Losses never stabilize\n",
    "- Generated samples don't improve\n",
    "- Quality oscillates between good and terrible\n",
    "\n",
    "### 4. Vanishing Gradients\n",
    "\n",
    "**When Discriminator is Too Good**:\n",
    "- $\\log(1 - D(G(z))) \\rightarrow -\\infty$ when $D(G(z)) \\rightarrow 1$\n",
    "- Generator gradients vanish → no learning\n",
    "- Training stagnates\n",
    "\n",
    "**Solution - Non-Saturating Loss**:\n",
    "- Instead of $\\min_G \\log(1 - D(G(z)))$\n",
    "- Use $\\max_G \\log(D(G(z)))$ (what we implement)\n",
    "\n",
    "### 5. Other Common Issues\n",
    "\n",
    "**Hyperparameter Sensitivity**:\n",
    "- Learning rates must be carefully balanced\n",
    "- Architecture choices heavily impact stability\n",
    "- Batch size affects training dynamics\n",
    "\n",
    "**Evaluation Difficulty**:\n",
    "- Loss values don't correlate with sample quality\n",
    "- Need external metrics (FID, IS, visual inspection)\n",
    "- Hard to know when to stop training\n",
    "\n",
    "**Memory and Computational Cost**:\n",
    "- Two networks instead of one\n",
    "- Adversarial training more expensive than standard training\n",
    "\n",
    "### Solutions and Mitigation Strategies\n",
    "\n",
    "**For Discriminator Collapse** (your issue):\n",
    "1. **Reduce discriminator learning rate**: `d_lr = 0.0001, g_lr = 0.0002`\n",
    "2. **Train generator more frequently**: 2-3 G updates per D update\n",
    "3. **Add noise to discriminator inputs**: `x + 0.1 * torch.randn_like(x)`\n",
    "4. **Use label smoothing**: Real labels = 0.9, Fake labels = 0.1\n",
    "5. **Reduce discriminator capacity**: Fewer layers or smaller hidden dims\n",
    "\n",
    "**For Mode Collapse**:\n",
    "1. **Minibatch discrimination**: Let discriminator see multiple samples\n",
    "2. **Unrolled GANs**: Generator considers future discriminator updates\n",
    "3. **Feature matching**: Generator matches statistics, not raw output\n",
    "\n",
    "**For Training Instability**:\n",
    "1. **WGAN**: Use Wasserstein distance instead of JS divergence\n",
    "2. **Spectral normalization**: Constrain discriminator Lipschitz constant\n",
    "3. **Progressive growing**: Start with low resolution, gradually increase\n",
    "4. **Self-attention**: Improve long-range dependencies\n",
    "\n",
    "**General Best Practices**:\n",
    "1. **Monitor multiple metrics**: Not just loss values\n",
    "2. **Save checkpoints frequently**: Training can suddenly diverge\n",
    "3. **Use proven architectures**: DCGAN, StyleGAN patterns\n",
    "4. **Patience**: GANs often need 100+ epochs to produce good results\n",
    "\n",
    "### Example of Healthy GAN Training\n",
    "\n",
    "**Good Loss Pattern**:\n",
    "```\n",
    "Epoch 1:  D_loss=1.2, G_loss=2.1, D(x)=0.8, D(G(z))=0.3\n",
    "Epoch 10: D_loss=0.8, G_loss=1.5, D(x)=0.7, D(G(z))=0.4  \n",
    "Epoch 50: D_loss=0.7, G_loss=0.9, D(x)=0.6, D(G(z))=0.5\n",
    "```\n",
    "\n",
    "**Indicators of Success**:\n",
    "- Both losses converge to ≈ 0.693 (log 2)\n",
    "- D(real) and D(fake) both approach 0.5\n",
    "- Generated samples show good diversity\n",
    "- Visual quality improves over time\n",
    "\n",
    "Understanding these challenges helps you diagnose issues and adjust training accordingly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images_gan(generator, epoch, nb_data=10, noise_dim=100, device='cpu'):\n",
    "    \"\"\"\n",
    "    Generate and display GAN sample images\n",
    "    \n",
    "    Process: z ~ N(0,I) → Generator → fake_images\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        # Sample random noise\n",
    "        noise = torch.randn(nb_data * nb_data, noise_dim).to(device)\n",
    "        fake_images = generator(noise).cpu().numpy()\n",
    "        \n",
    "        fig, axs = plt.subplots(nb_data, nb_data, figsize=(10, 10))\n",
    "        for i in range(nb_data):\n",
    "            for j in range(nb_data):\n",
    "                idx = i * nb_data + j\n",
    "                axs[i, j].imshow(fake_images[idx].reshape(28, 28), cmap='gray')\n",
    "                axs[i, j].set_xticks([])\n",
    "                axs[i, j].set_yticks([])\n",
    "        plt.suptitle(f'GAN Generated Images - Epoch {epoch}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    generator.train()\n",
    "\n",
    "\n",
    "def train_gan_improved(generator, discriminator, g_optimizer, d_optimizer, dataloader, \n",
    "                      nb_epochs=30, noise_dim=100, device='cpu'):\n",
    "    \"\"\"\n",
    "    Improved GAN training with fixes for common issues:\n",
    "    \n",
    "    Fixes implemented:\n",
    "    1. Label smoothing (prevents discriminator overconfidence)\n",
    "    2. Noisy inputs (adds regularization to discriminator) \n",
    "    3. Different learning rates (balances G/D power)\n",
    "    4. Multiple generator updates (helps with discriminator collapse)\n",
    "    5. Feature matching loss (encourages diversity)\n",
    "    \"\"\"\n",
    "    criterion = nn.BCELoss()\n",
    "    mse_loss = nn.MSELoss()  # For feature matching\n",
    "    \n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    \n",
    "    # Training hyperparameters for stability\n",
    "    label_smoothing = 0.1      # Real labels = 1-0.1, Fake labels = 0+0.1\n",
    "    noise_factor = 0.05        # Add noise to discriminator inputs\n",
    "    g_updates_per_d = 2        # Train generator more frequently\n",
    "    \n",
    "    print(\"=== Starting Improved GAN Training ===\")\n",
    "    print(f\"Fixes enabled:\")\n",
    "    print(f\"  - Label smoothing: {label_smoothing}\")\n",
    "    print(f\"  - Input noise factor: {noise_factor}\")\n",
    "    print(f\"  - Generator updates per D update: {g_updates_per_d}\")\n",
    "    print(f\"  - Feature matching loss\")\n",
    "    \n",
    "    for epoch in tqdm(range(nb_epochs), desc=\"Training Improved GAN\"):\n",
    "        epoch_g_loss = 0\n",
    "        epoch_d_loss = 0\n",
    "        \n",
    "        for batch_idx, real_images in enumerate(dataloader):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.to(device)\n",
    "            \n",
    "            # ===========================\n",
    "            # Train Discriminator (once per batch)\n",
    "            # ===========================\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            # FIX 1: Label smoothing - prevents overconfident discriminator\n",
    "            real_labels = torch.ones(batch_size, 1).to(device) * (1.0 - label_smoothing)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device) + label_smoothing\n",
    "            \n",
    "            # FIX 2: Add noise to real images - regularizes discriminator\n",
    "            real_images_noisy = real_images + noise_factor * torch.randn_like(real_images)\n",
    "            real_images_noisy = torch.clamp(real_images_noisy, 0, 1)  # Keep in valid range\n",
    "            \n",
    "            # Real images: should output ~0.9 (not 1.0)\n",
    "            real_outputs = discriminator(real_images_noisy)\n",
    "            d_loss_real = criterion(real_outputs, real_labels)\n",
    "            \n",
    "            # Fake images: should output ~0.1 (not 0.0)\n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            fake_images = generator(noise)\n",
    "            fake_outputs = discriminator(fake_images.detach())  # Detach to avoid generator gradients\n",
    "            d_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # ===========================\n",
    "            # Train Generator (multiple times per batch)\n",
    "            # FIX 3: Multiple generator updates helps with discriminator collapse\n",
    "            # ===========================\n",
    "            for g_step in range(g_updates_per_d):\n",
    "                g_optimizer.zero_grad()\n",
    "                \n",
    "                # Generate fake images and try to fool discriminator\n",
    "                noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "                fake_images = generator(noise)\n",
    "                fake_outputs = discriminator(fake_images)\n",
    "                \n",
    "                # Standard adversarial loss: want discriminator to output 1\n",
    "                g_loss_adv = criterion(fake_outputs, torch.ones(batch_size, 1).to(device))\n",
    "                \n",
    "                # FIX 4: Feature matching loss - encourages diversity\n",
    "                # Match statistics of intermediate features, not just final output\n",
    "                with torch.no_grad():\n",
    "                    real_features = discriminator.model[:-2](real_images)  # Features before final layer\n",
    "                fake_features = discriminator.model[:-2](fake_images)\n",
    "                g_loss_feature = mse_loss(fake_features.mean(0), real_features.mean(0))\n",
    "                \n",
    "                # Combined generator loss\n",
    "                g_loss = g_loss_adv + 0.1 * g_loss_feature  # Weight feature matching\n",
    "                \n",
    "                g_loss.backward()\n",
    "                g_optimizer.step()\n",
    "            \n",
    "            epoch_g_loss += g_loss.item()\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            \n",
    "            # Print loss components for monitoring - less frequent to avoid spam\n",
    "            if batch_idx % 200 == 0:  # Every 200 batches instead of 100\n",
    "                print(f\"Epoch {epoch+1:3d}, Batch {batch_idx:3d}: \"\n",
    "                      f\"D_loss={d_loss.item():6.3f}, G_loss={g_loss.item():6.3f}, \"\n",
    "                      f\"D(x)={real_outputs.mean().item():.3f}, \"\n",
    "                      f\"D(G(z))={fake_outputs.mean().item():.3f}\")\n",
    "                \n",
    "                # FIX 5: Better monitoring - warn about potential issues\n",
    "                d_real_mean = real_outputs.mean().item()\n",
    "                d_fake_mean = fake_outputs.mean().item()\n",
    "                \n",
    "                if d_real_mean > 0.95 and d_fake_mean < 0.05:\n",
    "                    print(\"  ⚠️  Discriminator dominating - consider reducing D learning rate\")\n",
    "                elif d_real_mean < 0.55 and d_fake_mean > 0.45:\n",
    "                    print(\"  ⚠️  Generator dominating - discriminator may need help\")\n",
    "                elif 0.3 < d_real_mean < 0.7 and 0.3 < d_fake_mean < 0.7:\n",
    "                    print(\"  ✓ Good balance between generator and discriminator\")\n",
    "        \n",
    "        # Store average losses\n",
    "        g_losses.append(epoch_g_loss / len(dataloader))\n",
    "        d_losses.append(epoch_d_loss / len(dataloader))\n",
    "        \n",
    "        # Generate images every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"\\nGenerating GAN images at epoch {epoch + 1}\")\n",
    "            generate_images_gan(generator, epoch + 1, device=device)\n",
    "            \n",
    "            # Additional diagnostics every 10 epochs\n",
    "            with torch.no_grad():\n",
    "                # Check diversity by generating many samples\n",
    "                diversity_noise = torch.randn(100, noise_dim).to(device)\n",
    "                diversity_samples = generator(diversity_noise)\n",
    "                diversity_std = diversity_samples.std().item()\n",
    "                \n",
    "                print(f\"Epoch {epoch + 1} Diagnostics:\")\n",
    "                print(f\"  Generator diversity (std): {diversity_std:.4f}\")\n",
    "                print(f\"  Average D(real): {d_real_mean:.3f}\")\n",
    "                print(f\"  Average D(fake): {d_fake_mean:.3f}\")\n",
    "                \n",
    "                if diversity_std < 0.1:\n",
    "                    print(\"  ⚠️  Low diversity - possible mode collapse!\")\n",
    "                elif diversity_std > 0.3:\n",
    "                    print(\"  ✓ Good sample diversity\")\n",
    "    \n",
    "    return g_losses, d_losses\n",
    "\n",
    "\n",
    "# Also create the original training function for comparison\n",
    "def train_gan_vanilla(generator, discriminator, g_optimizer, d_optimizer, dataloader, \n",
    "                     nb_epochs=30, noise_dim=100, device='cpu'):\n",
    "    \"\"\"\n",
    "    Original vanilla GAN training (prone to instability)\n",
    "    Kept for educational comparison\n",
    "    \"\"\"\n",
    "    criterion = nn.BCELoss()\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    \n",
    "    for epoch in tqdm(range(nb_epochs), desc=\"Training Vanilla GAN\"):\n",
    "        epoch_g_loss = 0\n",
    "        epoch_d_loss = 0\n",
    "        \n",
    "        for batch_idx, real_images in enumerate(dataloader):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.to(device)\n",
    "            \n",
    "            # Create labels (hard labels - problematic)\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)    # Hard 1.0\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)   # Hard 0.0\n",
    "            \n",
    "            # Train Discriminator\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            real_outputs = discriminator(real_images)  # No noise added\n",
    "            d_loss_real = criterion(real_outputs, real_labels)\n",
    "            \n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            fake_images = generator(noise)\n",
    "            fake_outputs = discriminator(fake_images.detach())\n",
    "            d_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "            \n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # Train Generator (only once - problematic)\n",
    "            g_optimizer.zero_grad()\n",
    "            \n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            fake_images = generator(noise)\n",
    "            fake_outputs = discriminator(fake_images)\n",
    "            g_loss = criterion(fake_outputs, real_labels)  # Only adversarial loss\n",
    "            \n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            epoch_g_loss += g_loss.item()\n",
    "            epoch_d_loss += d_loss.item()\n",
    "        \n",
    "        g_losses.append(epoch_g_loss / len(dataloader))\n",
    "        d_losses.append(epoch_d_loss / len(dataloader))\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            generate_images_gan(generator, epoch + 1, device=device)\n",
    "    \n",
    "    return g_losses, d_losses\n",
    "\n",
    "print(\"Training functions defined!\")\n",
    "print(\"Use train_gan_improved() for stable training with fixes\")\n",
    "print(\"Use train_gan_vanilla() for comparison (will likely fail)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GAN Model\n",
    "\n",
    "Let's train our GAN and observe the adversarial dynamics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup with improved hyperparameters\n",
    "dataloader = DataLoader(trainX, batch_size=128, shuffle=True)\n",
    "\n",
    "# FIX: Different learning rates for better balance  \n",
    "# Discriminator gets slower learning rate to prevent dominance\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))  # Slower!\n",
    "\n",
    "print(\"=== Improved GAN Training Setup ===\")\n",
    "print(f\"Generator learning rate: 0.0002\")\n",
    "print(f\"Discriminator learning rate: 0.0001 (slower to prevent dominance)\")\n",
    "print(f\"Batch size: 128\")\n",
    "print(f\"Training improvements enabled!\")\n",
    "\n",
    "# Test forward passes\n",
    "print(\"\\nTesting GAN forward passes...\")\n",
    "with torch.no_grad():\n",
    "    test_noise = torch.randn(5, noise_dim).to(device)\n",
    "    test_real = next(iter(dataloader))[:5].to(device)\n",
    "    \n",
    "    fake_test = generator(test_noise)\n",
    "    real_pred = discriminator(test_real)\n",
    "    fake_pred = discriminator(fake_test)\n",
    "    \n",
    "    print(f\"Test results:\")\n",
    "    print(f\"  Generator: {test_noise.shape} → {fake_test.shape}\")\n",
    "    print(f\"  Discriminator on real: {real_pred.mean().item():.3f}\")\n",
    "    print(f\"  Discriminator on fake: {fake_pred.mean().item():.3f}\")\n",
    "\n",
    "# Train improved GAN\n",
    "print(\"\\nStarting IMPROVED GAN training...\")\n",
    "print(\"This should be much more stable than vanilla GAN training!\")\n",
    "\n",
    "g_losses_improved, d_losses_improved = train_gan_improved(\n",
    "    generator, discriminator, g_optimizer, d_optimizer, \n",
    "    dataloader, nb_epochs=50, device=device  # More epochs since it's more stable\n",
    ")\n",
    "\n",
    "print(\"\\nImproved GAN training completed!\")\n",
    "\n",
    "# Optional: For educational comparison, you can also run vanilla training\n",
    "# (Uncomment the lines below to see the difference)\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARISON: Running Vanilla GAN (will likely fail)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Reset networks for fair comparison\n",
    "generator_vanilla = Generator(noise_dim=noise_dim).to(device)\n",
    "discriminator_vanilla = Discriminator().to(device)\n",
    "g_optimizer_vanilla = optim.Adam(generator_vanilla.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "d_optimizer_vanilla = optim.Adam(discriminator_vanilla.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "g_losses_vanilla, d_losses_vanilla = train_gan_vanilla(\n",
    "    generator_vanilla, discriminator_vanilla, g_optimizer_vanilla, d_optimizer_vanilla,\n",
    "    dataloader, nb_epochs=20, device=device\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing GAN Training Dynamics\n",
    "\n",
    "Let's visualize the training dynamics and understand what makes GANs challenging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "print(\"=== GAN Training Analysis ===\")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Loss curves\n",
    "plt.subplot(1, 3, 1)\n",
    "epochs = range(1, len(g_losses) + 1)\n",
    "plt.plot(epochs, g_losses, label='Generator Loss', color='blue')\n",
    "plt.plot(epochs, d_losses, label='Discriminator Loss', color='red')\n",
    "plt.axhline(y=0.693, color='green', linestyle='--', alpha=0.7, label='log(2) ≈ 0.693')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('GAN Training Losses')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Loss difference\n",
    "plt.subplot(1, 3, 2)\n",
    "loss_diff = np.array(g_losses) - np.array(d_losses)\n",
    "plt.plot(epochs, loss_diff, color='purple')\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.7)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Generator Loss - Discriminator Loss')\n",
    "plt.title('Training Balance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Loss moving average\n",
    "plt.subplot(1, 3, 3)\n",
    "window = 3\n",
    "if len(g_losses) >= window:\n",
    "    g_smooth = np.convolve(g_losses, np.ones(window)/window, mode='valid')\n",
    "    d_smooth = np.convolve(d_losses, np.ones(window)/window, mode='valid')\n",
    "    smooth_epochs = range(window, len(g_losses) + 1)\n",
    "    plt.plot(smooth_epochs, g_smooth, label='Generator (smoothed)', color='blue')\n",
    "    plt.plot(smooth_epochs, d_smooth, label='Discriminator (smoothed)', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Smoothed Loss')\n",
    "    plt.title('Smoothed Training Curves')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis\n",
    "final_g_loss = g_losses[-1]\n",
    "final_d_loss = d_losses[-1]\n",
    "loss_ratio = final_g_loss / final_d_loss\n",
    "\n",
    "print(f\"\\nTraining Analysis:\")\n",
    "print(f\"  Final Generator Loss: {final_g_loss:.3f}\")\n",
    "print(f\"  Final Discriminator Loss: {final_d_loss:.3f}\")\n",
    "print(f\"  Loss Ratio (G/D): {loss_ratio:.3f}\")\n",
    "print(f\"  Ideal target: Both ≈ 0.693 (log 2)\")\n",
    "\n",
    "if loss_ratio > 2.0:\n",
    "    print(\"  → Discriminator is winning (generator struggling)\")\n",
    "elif loss_ratio < 0.5:\n",
    "    print(\"  → Generator might be winning (discriminator struggling)\")\n",
    "else:\n",
    "    print(\"  → Reasonably balanced training\")\n",
    "\n",
    "# Test final model performance\n",
    "print(f\"\\n=== Final Model Performance ===\")\n",
    "with torch.no_grad():\n",
    "    # Test on real data\n",
    "    test_real = trainX[:100].to(device)\n",
    "    real_scores = discriminator(test_real)\n",
    "    \n",
    "    # Test on fake data\n",
    "    test_noise = torch.randn(100, noise_dim).to(device)\n",
    "    fake_images = generator(test_noise)\n",
    "    fake_scores = discriminator(fake_images)\n",
    "    \n",
    "    print(f\"Discriminator performance:\")\n",
    "    print(f\"  Real images score: {real_scores.mean().item():.3f} ± {real_scores.std().item():.3f}\")\n",
    "    print(f\"  Fake images score: {fake_scores.mean().item():.3f} ± {fake_scores.std().item():.3f}\")\n",
    "    print(f\"  Separation: {(real_scores.mean() - fake_scores.mean()).item():.3f}\")\n",
    "    \n",
    "    if real_scores.mean() > 0.7 and fake_scores.mean() < 0.3:\n",
    "        print(\"  → Discriminator still distinguishing well (may need more training)\")\n",
    "    elif 0.4 < real_scores.mean() < 0.6 and 0.4 < fake_scores.mean() < 0.6:\n",
    "        print(\"  → Good equilibrium reached!\")\n",
    "    else:\n",
    "        print(\"  → Training dynamics need adjustment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise-to-Image Mapping Analysis\n",
    "\n",
    "Let's explore how GANs map random noise to structured images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Noise-to-Image Mapping Analysis ===\")\n",
    "\n",
    "# Demonstrate noise interpolation\n",
    "def interpolate_noise(generator, z1, z2, steps=10):\n",
    "    \"\"\"Interpolate between two noise vectors\"\"\"\n",
    "    alphas = torch.linspace(0, 1, steps)\n",
    "    interpolations = []\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        z_interp = (1 - alpha) * z1 + alpha * z2\n",
    "        with torch.no_grad():\n",
    "            x_interp = generator(z_interp.unsqueeze(0))\n",
    "            interpolations.append(x_interp.cpu().numpy())\n",
    "    \n",
    "    return interpolations\n",
    "\n",
    "# Create noise interpolation\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    z1 = torch.randn(noise_dim).to(device)\n",
    "    z2 = torch.randn(noise_dim).to(device)\n",
    "    \n",
    "    interpolations = interpolate_noise(generator, z1, z2, steps=10)\n",
    "    \n",
    "    # Visualize interpolation\n",
    "    fig, axes = plt.subplots(2, 10, figsize=(15, 3))\n",
    "    \n",
    "    # First row: interpolation\n",
    "    for i, interp in enumerate(interpolations):\n",
    "        axes[0, i].imshow(interp.reshape(28, 28), cmap='gray')\n",
    "        axes[0, i].set_xticks([])\n",
    "        axes[0, i].set_yticks([])\n",
    "        axes[0, i].set_title(f'α={i/9:.1f}')\n",
    "    \n",
    "    # Second row: random samples for comparison\n",
    "    random_noise = torch.randn(10, noise_dim).to(device)\n",
    "    random_images = generator(random_noise).cpu().numpy()\n",
    "    \n",
    "    for i in range(10):\n",
    "        axes[1, i].imshow(random_images[i].reshape(28, 28), cmap='gray')\n",
    "        axes[1, i].set_xticks([])\n",
    "        axes[1, i].set_yticks([])\n",
    "        if i == 0:\n",
    "            axes[1, i].set_ylabel('Random')\n",
    "    \n",
    "    axes[0, 0].set_ylabel('Interpolation')\n",
    "    plt.suptitle('GAN Noise Space Structure')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analyze noise sensitivity\n",
    "print(\"\\nNoise sensitivity analysis:\")\n",
    "base_noise = torch.randn(noise_dim).to(device)\n",
    "base_image = generator(base_noise.unsqueeze(0))\n",
    "\n",
    "# Add small perturbations\n",
    "perturbations = [0.0, 0.1, 0.5, 1.0, 2.0]\n",
    "perturbed_images = []\n",
    "\n",
    "for eps in perturbations:\n",
    "    perturbed_noise = base_noise + eps * torch.randn_like(base_noise)\n",
    "    with torch.no_grad():\n",
    "        perturbed_image = generator(perturbed_noise.unsqueeze(0))\n",
    "        perturbed_images.append(perturbed_image.cpu().numpy())\n",
    "        \n",
    "        # Compute image difference\n",
    "        diff = torch.mean((perturbed_image - base_image) ** 2).item()\n",
    "        print(f\"  Noise perturbation {eps:.1f} → Image MSE: {diff:.4f}\")\n",
    "\n",
    "# Visualize perturbations\n",
    "fig, axes = plt.subplots(1, len(perturbations), figsize=(12, 2))\n",
    "for i, (eps, img) in enumerate(zip(perturbations, perturbed_images)):\n",
    "    axes[i].imshow(img.reshape(28, 28), cmap='gray')\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "    axes[i].set_title(f'ε = {eps:.1f}')\n",
    "\n",
    "plt.suptitle('Effect of Noise Perturbations')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ GANs learn a smooth mapping from noise to images!\")\n",
    "print(\"✓ Small noise changes lead to gradual image changes\")\n",
    "print(\"✓ Large noise changes can produce completely different digits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways: GANs vs Other Generative Models\n",
    "\n",
    "### Advantages of GANs\n",
    "1. **Sharp, High-Quality Images**: No blurriness like VAEs\n",
    "2. **No Explicit Likelihood**: Focuses purely on sample quality\n",
    "3. **Flexible Architectures**: Can use any differentiable networks\n",
    "4. **Direct Sampling**: Simple noise-to-image mapping\n",
    "5. **Scalable**: Works well with large, complex datasets\n",
    "\n",
    "### Limitations of GANs\n",
    "1. **Training Instability**: Sensitive to hyperparameters, architecture\n",
    "2. **Mode Collapse**: May generate limited variety\n",
    "3. **No Likelihood**: Cannot evaluate probability of data\n",
    "4. **Difficult Evaluation**: Requires external metrics (FID, IS)\n",
    "5. **No Latent Inference**: Cannot encode data to latent space\n",
    "\n",
    "### Training Challenges\n",
    "1. **Nash Equilibrium**: Hard to reach stable equilibrium\n",
    "2. **Gradient Issues**: Vanishing/exploding gradients\n",
    "3. **Hyperparameter Sensitivity**: Learning rates, architectures\n",
    "4. **Monitoring**: Loss values don't directly indicate quality\n",
    "\n",
    "### Comparison Summary\n",
    "\n",
    "| Aspect | GAN | VAE | Real NVP |\n",
    "|--------|-----|-----|----------|\n",
    "| **Sample Quality** | Excellent | Blurry | Good |\n",
    "| **Training Stability** | Unstable | Stable | Stable |\n",
    "| **Likelihood** | None | Lower bound | Exact |\n",
    "| **Latent Space** | Not guaranteed | Meaningful | Meaningful |\n",
    "| **Mode Coverage** | Can collapse | Good | Good |\n",
    "| **Evaluation** | External metrics | Likelihood | Likelihood |\n",
    "\n",
    "### Modern GAN Improvements\n",
    "- **DCGAN**: Convolutional architectures\n",
    "- **WGAN**: Wasserstein distance for stability\n",
    "- **StyleGAN**: Style-based generation\n",
    "- **Progressive GAN**: Progressive growing\n",
    "- **Spectral Normalization**: Training stability\n",
    "\n",
    "### Best Practices for GANs\n",
    "- **Architecture**: Use DCGAN-style convolutions for images\n",
    "- **Learning Rates**: Often different for G and D\n",
    "- **Batch Normalization**: Helps training stability\n",
    "- **Feature Matching**: Alternative generator objective\n",
    "- **Multiple Updates**: Train D multiple times per G update\n",
    "\n",
    "---\n",
    "\n",
    "**References:**\n",
    "- Goodfellow, I., et al. (2014). Generative adversarial nets. NIPS.\n",
    "- Radford, A., Metz, L., & Chintala, S. (2015). Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434.\n",
    "- Arjovsky, M., Chintala, S., & Bottou, L. (2017). Wasserstein generative adversarial networks. ICML."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}